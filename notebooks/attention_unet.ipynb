{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16bcb176-cf04-4e12-9d30-8eafbff277e1",
   "metadata": {},
   "source": [
    "# Name: Luke Pratley\n",
    "\n",
    "# Testing AttentionUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a62c40-9d58-4599-a894-649dc02bed87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\nimport tensorflow.keras \\nimport tensorflow as tf\\n\\nimport tensorboard\\n\\nfrom datetime import datetime\\n\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nimport PIL\\nimport math\\n\\nimport sys\\nimport glob\\nimport os\\n\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\n\\nsys.path.append('..')\\n\\nimport building_road_segmentation.unet_factory as unet_factory\\nimport building_road_segmentation.optimization_factory as optimization_factory\\nimport building_road_segmentation.data_generator as data_generator\\nimport building_road_segmentation.loss_functions as loss_functions\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\nimport tensorflow.keras\\nimport tensorflow as tf\\n\\nimport tensorboard\\n\\nfrom datetime import datetime\\n\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nimport PIL\\nimport math\\n\\nimport sys\\nimport glob\\nimport os\\n\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import classification_report\\n\\nsys.path.append(\\\"..\\\")\\n\\nimport building_road_segmentation.unet_factory as unet_factory\\nimport building_road_segmentation.optimization_factory as optimization_factory\\nimport building_road_segmentation.data_generator as data_generator\\nimport building_road_segmentation.loss_functions as loss_functions\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "import tensorflow.keras \n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import math\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import building_road_segmentation.unet_factory as unet_factory\n",
    "import building_road_segmentation.optimization_factory as optimization_factory\n",
    "import building_road_segmentation.data_generator as data_generator\n",
    "import building_road_segmentation.loss_functions as loss_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9fbacd-ebdc-494e-9f57-206abb7e662a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"image_dir =  glob.glob(\\\"..\\\\\\\\data_cleaning_EDA\\\\\\\\final_images_small\\\\\\\\*\\\")\\nmask_dir =  glob.glob(\\\"..\\\\\\\\data_cleaning_EDA\\\\\\\\final_masks_small\\\\\\\\*\\\")\\nfor p in range(len(image_dir)):\\n    s1 = image_dir[p].split('\\\\\\\\')[-1].replace('RGB-PanSharpen_', '').replace('.png', '')\\n    s2 = mask_dir[p].split('\\\\\\\\')[-1].replace('RGB-PanSharpen_', '').replace('.npy', '')\\n    assert s1 == s2\";\n",
       "                var nbb_formatted_code = \"image_dir = glob.glob(\\\"..\\\\\\\\data_cleaning_EDA\\\\\\\\final_images_small\\\\\\\\*\\\")\\nmask_dir = glob.glob(\\\"..\\\\\\\\data_cleaning_EDA\\\\\\\\final_masks_small\\\\\\\\*\\\")\\nfor p in range(len(image_dir)):\\n    s1 = image_dir[p].split(\\\"\\\\\\\\\\\")[-1].replace(\\\"RGB-PanSharpen_\\\", \\\"\\\").replace(\\\".png\\\", \\\"\\\")\\n    s2 = mask_dir[p].split(\\\"\\\\\\\\\\\")[-1].replace(\\\"RGB-PanSharpen_\\\", \\\"\\\").replace(\\\".npy\\\", \\\"\\\")\\n    assert s1 == s2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_dir =  glob.glob(\"..\\\\data_cleaning_EDA\\\\final_images_small\\\\*\")\n",
    "mask_dir =  glob.glob(\"..\\\\data_cleaning_EDA\\\\final_masks_small\\\\*\")\n",
    "for p in range(len(image_dir)):\n",
    "    s1 = image_dir[p].split('\\\\')[-1].replace('RGB-PanSharpen_', '').replace('.png', '')\n",
    "    s2 = mask_dir[p].split('\\\\')[-1].replace('RGB-PanSharpen_', '').replace('.npy', '')\n",
    "    assert s1 == s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f46eb4-f4ab-4a7b-b302-91c9fd1a4baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"train_image_dir, test_image_dir, train_mask_dir, test_mask_dir = train_test_split(image_dir, mask_dir, test_size=0.3, random_state=42)\";\n",
       "                var nbb_formatted_code = \"train_image_dir, test_image_dir, train_mask_dir, test_mask_dir = train_test_split(\\n    image_dir, mask_dir, test_size=0.3, random_state=42\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_image_dir, test_image_dir, train_mask_dir, test_mask_dir = train_test_split(image_dir, mask_dir, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357b9a84-251a-4712-879d-c5db2b251d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"train_data = data_generator.READ_AND_AUGMENT_DATA(train_image_dir, train_mask_dir, batch_size=64)\\ntest_data = data_generator.READ_DATA(test_image_dir, test_mask_dir, batch_size=128)\";\n",
       "                var nbb_formatted_code = \"train_data = data_generator.READ_AND_AUGMENT_DATA(\\n    train_image_dir, train_mask_dir, batch_size=64\\n)\\ntest_data = data_generator.READ_DATA(test_image_dir, test_mask_dir, batch_size=128)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = data_generator.READ_AND_AUGMENT_DATA(train_image_dir, train_mask_dir, batch_size=64)\n",
    "test_data = data_generator.READ_DATA(test_image_dir, test_mask_dir, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65025afa-8570-40ba-8894-b8e1f07954b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"losses = {'dice_loss' : loss_functions.weighted_dice_loss([1, 1]), 'BinaryCrossentropy': tf.keras.losses.BinaryCrossentropy()}\";\n",
       "                var nbb_formatted_code = \"losses = {\\n    \\\"dice_loss\\\": loss_functions.weighted_dice_loss([1, 1]),\\n    \\\"BinaryCrossentropy\\\": tf.keras.losses.BinaryCrossentropy(),\\n}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = {'dice_loss' : loss_functions.weighted_dice_loss([1, 1]), 'BinaryCrossentropy': tf.keras.losses.BinaryCrossentropy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b599c6-16a0-4368-aa50-db30dabefb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"model_configurations = {'attention_model_1': {'unet_levels': 4, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': False, 'loss': 'dice_loss'},\\n                        'attention_model_2': {'unet_levels': 4, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': False, 'loss': 'BinaryCrossentropy'},\\n                        'attention_model_3': {'unet_levels': 5, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': False, 'loss': 'dice_loss'},\\n                        'attention_model_4': {'unet_levels': 5, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': False, 'loss': 'BinaryCrossentropy'},\\n                        'attention_res_model_1': {'unet_levels': 4, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': True, 'loss': 'dice_loss'},\\n                        'attention_res_model_2': {'unet_levels': 4, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': True, 'loss': 'BinaryCrossentropy'},\\n                        'attention_res_model_3': {'unet_levels': 5, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': True, 'loss': 'dice_loss'},\\n                        'attention_res_model_4': {'unet_levels': 5, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': True, 'loss': 'BinaryCrossentropy'},\\n                       }\\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\";\n",
       "                var nbb_formatted_code = \"model_configurations = {\\n    \\\"attention_model_1\\\": {\\n        \\\"unet_levels\\\": 4,\\n        \\\"number_of_start_kernels\\\": 32,\\n        \\\"pooling_amount\\\": 2,\\n        \\\"residual\\\": False,\\n        \\\"loss\\\": \\\"dice_loss\\\",\\n    },\\n    \\\"attention_model_2\\\": {\\n        \\\"unet_levels\\\": 4,\\n        \\\"number_of_start_kernels\\\": 32,\\n        \\\"pooling_amount\\\": 2,\\n        \\\"residual\\\": False,\\n        \\\"loss\\\": \\\"BinaryCrossentropy\\\",\\n    },\\n    \\\"attention_model_3\\\": {\\n        \\\"unet_levels\\\": 5,\\n        \\\"number_of_start_kernels\\\": 32,\\n        \\\"pooling_amount\\\": 2,\\n        \\\"residual\\\": False,\\n        \\\"loss\\\": \\\"dice_loss\\\",\\n    },\\n    \\\"attention_model_4\\\": {\\n        \\\"unet_levels\\\": 5,\\n        \\\"number_of_start_kernels\\\": 32,\\n        \\\"pooling_amount\\\": 2,\\n        \\\"residual\\\": False,\\n        \\\"loss\\\": \\\"BinaryCrossentropy\\\",\\n    },\\n    \\\"attention_res_model_1\\\": {\\n        \\\"unet_levels\\\": 4,\\n        \\\"number_of_start_kernels\\\": 32,\\n        \\\"pooling_amount\\\": 2,\\n        \\\"residual\\\": True,\\n        \\\"loss\\\": \\\"dice_loss\\\",\\n    },\\n    \\\"attention_res_model_2\\\": {\\n        \\\"unet_levels\\\": 4,\\n        \\\"number_of_start_kernels\\\": 32,\\n        \\\"pooling_amount\\\": 2,\\n        \\\"residual\\\": True,\\n        \\\"loss\\\": \\\"BinaryCrossentropy\\\",\\n    },\\n    \\\"attention_res_model_3\\\": {\\n        \\\"unet_levels\\\": 5,\\n        \\\"number_of_start_kernels\\\": 32,\\n        \\\"pooling_amount\\\": 2,\\n        \\\"residual\\\": True,\\n        \\\"loss\\\": \\\"dice_loss\\\",\\n    },\\n    \\\"attention_res_model_4\\\": {\\n        \\\"unet_levels\\\": 5,\\n        \\\"number_of_start_kernels\\\": 32,\\n        \\\"pooling_amount\\\": 2,\\n        \\\"residual\\\": True,\\n        \\\"loss\\\": \\\"BinaryCrossentropy\\\",\\n    },\\n}\\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_configurations = {'attention_model_1': {'unet_levels': 4, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': False, 'loss': 'dice_loss'},\n",
    "                        'attention_model_2': {'unet_levels': 4, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': False, 'loss': 'BinaryCrossentropy'},\n",
    "                        'attention_model_3': {'unet_levels': 5, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': False, 'loss': 'dice_loss'},\n",
    "                        'attention_model_4': {'unet_levels': 5, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': False, 'loss': 'BinaryCrossentropy'},\n",
    "                        'attention_res_model_1': {'unet_levels': 4, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': True, 'loss': 'dice_loss'},\n",
    "                        'attention_res_model_2': {'unet_levels': 4, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': True, 'loss': 'BinaryCrossentropy'},\n",
    "                        'attention_res_model_3': {'unet_levels': 5, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': True, 'loss': 'dice_loss'},\n",
    "                        'attention_res_model_4': {'unet_levels': 5, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': True, 'loss': 'BinaryCrossentropy'},\n",
    "                       }\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed8cf8-b60c-416b-b041-5bdc10646285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_model_1 {'unet_levels': 4, 'number_of_start_kernels': 32, 'pooling_amount': 2, 'residual': False, 'loss': 'dice_loss'}\n",
      "Epoch 1/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.6596INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 106s 383ms/step - loss: 0.4977 - accuracy: 0.6596 - val_loss: 0.6234 - val_accuracy: 0.6023\n",
      "Epoch 2/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.7101INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 98s 371ms/step - loss: 0.3871 - accuracy: 0.7101 - val_loss: 0.4646 - val_accuracy: 0.8086\n",
      "Epoch 3/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.3558 - accuracy: 0.7081INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 92s 352ms/step - loss: 0.3558 - accuracy: 0.7081 - val_loss: 0.4069 - val_accuracy: 0.7239\n",
      "Epoch 4/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.7012INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 95s 364ms/step - loss: 0.3375 - accuracy: 0.7012 - val_loss: 0.3369 - val_accuracy: 0.7183\n",
      "Epoch 5/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.3234 - accuracy: 0.6981INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 98s 372ms/step - loss: 0.3234 - accuracy: 0.6981 - val_loss: 0.3317 - val_accuracy: 0.7178\n",
      "Epoch 6/100\n",
      "262/262 [==============================] - 85s 323ms/step - loss: 0.3137 - accuracy: 0.6999 - val_loss: 0.3516 - val_accuracy: 0.6939\n",
      "Epoch 7/100\n",
      "262/262 [==============================] - 82s 313ms/step - loss: 0.3050 - accuracy: 0.7017 - val_loss: 0.3334 - val_accuracy: 0.7913\n",
      "Epoch 8/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.2967 - accuracy: 0.7127INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 93s 357ms/step - loss: 0.2967 - accuracy: 0.7127 - val_loss: 0.3262 - val_accuracy: 0.7549\n",
      "Epoch 9/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.7165INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 96s 365ms/step - loss: 0.2904 - accuracy: 0.7165 - val_loss: 0.3008 - val_accuracy: 0.7551\n",
      "Epoch 10/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.2850 - accuracy: 0.7240INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 94s 359ms/step - loss: 0.2850 - accuracy: 0.7240 - val_loss: 0.2977 - val_accuracy: 0.6977\n",
      "Epoch 11/100\n",
      "262/262 [==============================] - 83s 315ms/step - loss: 0.2806 - accuracy: 0.7338 - val_loss: 0.2994 - val_accuracy: 0.6734\n",
      "Epoch 12/100\n",
      "262/262 [==============================] - 82s 313ms/step - loss: 0.2755 - accuracy: 0.7386 - val_loss: 0.3294 - val_accuracy: 0.7268\n",
      "Epoch 13/100\n",
      "262/262 [==============================] - 83s 315ms/step - loss: 0.2716 - accuracy: 0.7459 - val_loss: 0.3059 - val_accuracy: 0.7551\n",
      "Epoch 14/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.2688 - accuracy: 0.7481INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 96s 366ms/step - loss: 0.2688 - accuracy: 0.7481 - val_loss: 0.2911 - val_accuracy: 0.7795\n",
      "Epoch 15/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.7517INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 95s 362ms/step - loss: 0.2644 - accuracy: 0.7517 - val_loss: 0.2853 - val_accuracy: 0.7044\n",
      "Epoch 16/100\n",
      "262/262 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.7596INFO:tensorflow:Assets written to: attention_model_1\\assets\n",
      "262/262 [==============================] - 98s 372ms/step - loss: 0.2619 - accuracy: 0.7596 - val_loss: 0.2754 - val_accuracy: 0.7764\n",
      "Epoch 17/100\n",
      " 16/262 [>.............................] - ETA: 1:17 - loss: 0.2591 - accuracy: 0.7406"
     ]
    }
   ],
   "source": [
    "for model_name, model_config in model_configurations.items():\n",
    "    print(model_name, model_config)\n",
    "    if not os.path.exists(model_name):\n",
    "        unet_model = unet_factory.BasicUNet(number_of_categories=2,\n",
    "                                            unet_levels=model_config['unet_levels'],\n",
    "                                            number_of_start_kernels=model_config['number_of_start_kernels'],\n",
    "                                            kernel_shape=(3, 3),\n",
    "                                            activation='relu',\n",
    "                                            final_activation='sigmoid',\n",
    "                                            pooling_amount=model_config['pooling_amount'],\n",
    "                                            dropout_rate=0.2, residual=model_config['residual'])\n",
    "\n",
    "        modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath=model_name, \n",
    "                        monitor='val_loss',\n",
    "                        mode='min',\n",
    "                        save_best_only=True)\n",
    "        unet_model.compile(optimizer=optimizer, loss=losses[model_config['loss']], metrics=['accuracy'])\n",
    "        history = unet_model.fit(train_data, epochs=100, validation_data=test_data, callbacks=[modelcheckpoint])\n",
    "        history = pd.DataFrame(history.history) \n",
    "        history.to_csv(f'{model_name}_history.csv')  \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b61a5-e5c5-41d0-9a4a-b96be3490e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "histories = []\n",
    "for model_name, model_config in model_configurations.items():\n",
    "    if os.path.exists(model_name):\n",
    "        histories.append(pd.read_csv(model_name +'_history.csv'))\n",
    "    # summarize history for accuracy\n",
    "for history in histories:\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798299c1-d664-4747-9da3-5bf60f3814ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([np.array(PIL.Image.open(im)).astype(float) for im in test_image_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd83d31-1913-43e2-b984-cd6eb60a3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([\n",
    "            np.load(file_name)\n",
    "               for file_name in test_mask_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda246d6-8a6f-42fe-89e6-38b1cf4dbbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iou_metric = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "for k, (model_name, model_config) in enumerate(model_configurations.items()):\n",
    "    if os.path.exists(model_name):\n",
    "        final_model = tf.keras.models.load_model(model_name, custom_objects={model_config['loss']: losses[model_config['loss']]})\n",
    "        print(model_config)\n",
    "        y_pred = final_model.predict(X_test/255)\n",
    "        y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "        print(np.mean([loss_functions.intersection_over_union(y_test[k, :, :, 0], y_pred[k, :, :, 0]) for k in range(y_test.shape[0])]))\n",
    "        print(np.mean([loss_functions.intersection_over_union(y_test[k, :, :, 1], y_pred[k, :, :, 1]) for k in range(y_test.shape[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f01b42-ba67-4b36-a0d4-70bf67b6c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(X_test, y_test, model_name, display_prob, index=0):\n",
    "    if os.path.exists(model_name):\n",
    "        final_model = tf.keras.models.load_model(model_name, custom_objects={model_config['loss']: losses[model_config['loss']]})\n",
    "        y_pred = final_model.predict(X_test)\n",
    "        if not display_prob:\n",
    "            y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "        fig, ax = plt.subplots(2, 3, figsize=(20, 10), sharex=True, sharey=True)\n",
    "        ax[0, 0].imshow((X_test[index] * 255).astype(int), vmin=0, vmax=255)\n",
    "        ax[1, 0].imshow(y_test[index, :, :, 0] * 0.5 + y_test[index, :, :, 1] * 0.25, vmin = 0)\n",
    "        ax[1, 1].imshow(y_test[index, :, :, 0], vmin = 0, vmax=1)\n",
    "        ax[1, 2].imshow(y_test[index, :, :, 1], vmin = 0, vmax=1)\n",
    "        ax[0, 1].imshow(y_pred[index, :, :, 0], vmin = 0, vmax=1)\n",
    "        ax[0, 2].imshow(y_pred[index, :, :, 1], vmin = 0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae9819-72e3-402f-a5a3-5974cc0d697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "for model_name, model_config in model_configurations.items():\n",
    "    print(model_config)\n",
    "    batch = math.ceil(k / test_data.batch_size)\n",
    "    X_test, y_test = test_data.__getitem__(batch)\n",
    "    plot_result(X_test, y_test, model_name=model_name, display_prob=True, index=k - batch * test_data.batch_size)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d257d8c-efc3-41d3-9d4a-8d80ca0fdaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
